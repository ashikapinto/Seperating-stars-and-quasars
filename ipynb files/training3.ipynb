{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "#Upsampling\n",
    "data=pd.read_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\ML\\\\catalog3\\\\cat3.csv')\n",
    "df_majority=data[data['class']==1]\n",
    "df_minority = data[data['class']==0]\n",
    "df_minority_random=df_minority.sample(n=len(df_majority),replace=True)\n",
    "df_upsampled=pd.concat([df_majority,df_minority_random],axis=0)\n",
    "\n",
    "#splitting into y and x\n",
    "y=df_upsampled['class']\n",
    "#converting into np.array\n",
    "y=y.values\n",
    "#dropping some of the variables\n",
    "x=df_upsampled.drop('class',axis=1)\n",
    "x=x.drop('galex_objid',axis=1)\n",
    "x=x.drop('sdss_objid',axis=1)\n",
    "x=x.drop('spectrometric_redshift',axis=1)\n",
    "x=x.drop('pred',axis=1)\n",
    "x=x.drop('Unnamed: 0',axis=1)\n",
    "#converting into np.array\n",
    "x=x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_into_train_test(x, y):\n",
    "    A = np.random.rand(x.shape[0])\n",
    "    s = A < np.percentile(A, 70)\n",
    "    #print(split)\n",
    "    X_test =  x[~s]\n",
    "    y_test = y[~s]\n",
    "    X_train = x[s]\n",
    "    y_train = y[s]\n",
    "    #print(len(X_train), len(y_train), len(X_test), len(y_test))\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "#Splitting into train and test data sets\n",
    "X_train, y_train, X_test, y_test = split_into_train_test(x,y) \n",
    "\n",
    "#Next we need to transform all the attributes to have 0 mean and standard deviation 1.This is essential because the larger \n",
    "#ranged attributes should not affect/contribute to the result more that the others.\n",
    "#i.e in the below functions we are imitating what the standard scalar function does.\n",
    "\n",
    "#Function to calculate the mean of each of the columns\n",
    "def mean(df):\n",
    "    means_of_cols = [0 for i in range(len(df[0]))]\n",
    "    for i in range(len(df[0])):\n",
    "        column = [row[i] for row in df]\n",
    "        means_of_cols[i] = sum(column) / float(len(df))\n",
    "    return means_of_cols\n",
    "\n",
    "#Function to calculate the standard deviations of each of the columns\n",
    "def standard_deviation(df, means_of_cols):\n",
    "    std_of_cols = [0 for i in range(len(df[0]))]\n",
    "    for i in range(len(df[0])):\n",
    "        variance = [pow(x[i]-means_of_cols[i], 2) for x in df]\n",
    "        std_of_cols[i] = sum(variance)\n",
    "    std_of_cols = [sqrt(x/(float(len(df)-1))) for x in std_of_cols]\n",
    "    return std_of_cols\n",
    "\n",
    "# standardize\n",
    "def standardize(df, means_of_cols, std_of_cols):\n",
    "    for row in df:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - means_of_cols[i]) / std_of_cols[i]\n",
    "\n",
    "\n",
    "means_of_cols = mean(X_train)\n",
    "std_of_cols = standard_deviation(X_train, means_of_cols)\n",
    "\n",
    "\n",
    "standardize(X_train, means_of_cols, std_of_cols)\n",
    "standardize(X_test, means_of_cols, std_of_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# function to calculate euclidean distance\n",
    "def distance(x1, x2, n):\n",
    "    d = 0\n",
    "    for x in range(n):\n",
    "        d += np.square(x1[x] - x2[x])\n",
    "    return np.sqrt(d)\n",
    "\n",
    "# KNN model\n",
    "def knn(train, test_row, k):\n",
    "    dist = {}\n",
    "    n = test_row.shape[0]\n",
    "    for x in range(len(train)):\n",
    "        d = distance(test_row, train[x], n)\n",
    "        dist[x] = d\n",
    "    #Ordered_dist contains the row numbers of the rows of the training data set ordered in the ascending order of \n",
    "    #the distance to the test instance\n",
    "    ordered_dist = sorted(dist.items(), key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for i in range(k):\n",
    "        neighbors.append(ordered_dist[i][0])\n",
    "    #Neighbors contains only the first K elements of the Ordered_dist\n",
    "    counts = {}  \n",
    "    for i in range(len(neighbors)):\n",
    "        target = y_train[neighbors[i]]\n",
    "        if target in counts:\n",
    "            counts[target] += 1\n",
    "        else:\n",
    "            counts[target] = 1\n",
    "    #Counts is a dictionary that keeps track of how many votes each of the outputs have recieved \n",
    "    ordered_count = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #Ordered count sorts this dictionary based on the number of votes and the function returns the target class with the maximum\n",
    "    #number of votes\n",
    "    return (ordered_count[0][0]) \n",
    "\n",
    "#Applying the model on the test data and storing the output in a list called predictions\n",
    "predictions=[]\n",
    "for i in range(len(X_test)):\n",
    "    predictions.append(knn(X_train,X_test[i],3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for catalog 3\n",
      "97.6470588235294\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_test, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(y_test)):\n",
    "        if y_test[x] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(y_test))) * 100.0\n",
    "\n",
    "print(\"accuracy for catalog 3\")\n",
    "print(accuracy(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives:  1084\n",
      "False positives:  26\n",
      "True negatives:  1157\n",
      "False negatives:  28\n",
      "class 1 accuracy: 97.48201438848922\n",
      "class 0 accuracy: 97.8021978021978\n",
      "recall:  0.9748201438848921 \n",
      "precision:  0.9765765765765766 \n",
      "FPR : 0.02197802197802198 \n",
      "Fscore : 0.9756975697569759\n"
     ]
    }
   ],
   "source": [
    "def confusionmatrix(y_actual, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    l0=0\n",
    "    l1=0\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_actual[i]==0):\n",
    "            l0+=1\n",
    "        elif(y_actual[i]==1):\n",
    "            l1+=1\n",
    "        if y_actual[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "    return(TP, FP, TN, FN,l0,l1)\n",
    "\n",
    "TP,FP,TN,FN,l0,l1=confusionmatrix(y_test,predictions)\n",
    "print(\"True positives: \",TP)\n",
    "print(\"False positives: \",FP)\n",
    "print(\"True negatives: \",TN)\n",
    "print(\"False negatives: \",FN)\n",
    "print(\"class 1 accuracy:\",((TP/l1)*100))\n",
    "print(\"class 0 accuracy:\",((TN/l0)*100))\n",
    "recall=TP/(TP+FN)\n",
    "precision=TP/(TP+FP)\n",
    "false_pos_rate=FP/(FP+TN)\n",
    "fscore=(2*recall*precision)/(recall+precision)\n",
    "print(\"recall: \",recall,\"\\nprecision: \",precision,\"\\nFPR :\",false_pos_rate,\"\\nFscore :\",fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies for catalog 1\n",
      "99.74789915966386\n",
      "True positives:  592\n",
      "False positives:  0\n",
      "True negatives:  595\n",
      "False negatives:  3\n",
      "recall:  0.9949579831932773 \n",
      "precision:  1.0 \n",
      "FPR : 0.0 \n",
      "Fscore : 0.9974726200505476\n"
     ]
    }
   ],
   "source": [
    "#Catalog 1:\n",
    "#Now we test the catalog 1 on the model built on catalog 3\n",
    "data=pd.read_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\ML\\\\catalog1\\\\cat1.csv')\n",
    "df_majority=data[data['class']==1]\n",
    "df_minority = data[data['class']==0]\n",
    "df_minority_random=df_minority.sample(n=len(df_majority),replace=True)\n",
    "df_upsampled=pd.concat([df_majority,df_minority_random],axis=0)\n",
    "\n",
    "#splitting into y and x\n",
    "y=df_upsampled['class']\n",
    "#converting into np.array\n",
    "y=y.values\n",
    "#dropping some of the variables\n",
    "x=df_upsampled.drop('class',axis=1)\n",
    "x=x.drop('galex_objid',axis=1)\n",
    "x=x.drop('sdss_objid',axis=1)\n",
    "x=x.drop('spectrometric_redshift',axis=1)\n",
    "x=x.drop('pred',axis=1)\n",
    "x=x.drop('Unnamed: 0',axis=1)\n",
    "#converting into np.array\n",
    "x=x.values\n",
    "\n",
    "\n",
    "standardize(x, means_of_cols, std_of_cols)\n",
    "predictions=[]\n",
    "for i in range(len(x)):\n",
    "    predictions.append(knn(X_train,x[i],3))\n",
    "print(\"accuracies for catalog 1\")    \n",
    "print(accuracy(y,predictions))\n",
    "TP,FP,TN,FN=confusionmatrix(y,predictions)\n",
    "print(\"True positives: \",TP)\n",
    "print(\"False positives: \",FP)\n",
    "print(\"True negatives: \",TN)\n",
    "print(\"False negatives: \",FN)\n",
    "\n",
    "\n",
    "recall=TP/(TP+FN)\n",
    "precision=TP/(TP+FP)\n",
    "false_pos_rate=FP/(FP+TN)\n",
    "fscore=(2*recall*precision)/(recall+precision)\n",
    "print(\"recall: \",recall,\"\\nprecision: \",precision,\"\\nFPR :\",false_pos_rate,\"\\nFscore :\",fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies for catalog 2\n",
      "98.5908950139362\n",
      "True positives:  3202\n",
      "False positives:  64\n",
      "True negatives:  3165\n",
      "False negatives:  27\n",
      "recall:  0.9916382781046764 \n",
      "precision:  0.9804041641151255 \n",
      "FPR : 0.019820377825952307 \n",
      "Fscore : 0.9859892224788299\n"
     ]
    }
   ],
   "source": [
    "#Catalog 2:\n",
    "#Now we test the catalog 2 on the model built on catalog 3\n",
    "data=pd.read_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\ML\\\\catalog2\\\\cat2.csv')\n",
    "df_majority=data[data['class']==1]\n",
    "df_minority = data[data['class']==0]\n",
    "df_minority_random=df_minority.sample(n=len(df_majority),replace=True)\n",
    "df_upsampled=pd.concat([df_majority,df_minority_random],axis=0)\n",
    "\n",
    "#splitting into y and x\n",
    "y=df_upsampled['class']\n",
    "#converting into np.array\n",
    "y=y.values\n",
    "#dropping some of the variables\n",
    "x=df_upsampled.drop('class',axis=1)\n",
    "x=x.drop('galex_objid',axis=1)\n",
    "x=x.drop('sdss_objid',axis=1)\n",
    "x=x.drop('spectrometric_redshift',axis=1)\n",
    "x=x.drop('pred',axis=1)\n",
    "x=x.drop('Unnamed: 0',axis=1)\n",
    "x=x.drop('Unnamed: 0.1',axis=1)\n",
    "#converting into np.array\n",
    "x=x.values\n",
    "\n",
    "\n",
    "standardize(x, means_of_cols, std_of_cols)\n",
    "predictions=[]\n",
    "for i in range(len(x)):\n",
    "    predictions.append(knn(X_train,x[i],3))\n",
    "print(\"accuracies for catalog 2\")\n",
    "print(accuracy(y,predictions))\n",
    "TP,FP,TN,FN=confusionmatrix(y,predictions)\n",
    "print(\"True positives: \",TP)\n",
    "print(\"False positives: \",FP)\n",
    "print(\"True negatives: \",TN)\n",
    "print(\"False negatives: \",FN)\n",
    "\n",
    "\n",
    "recall=TP/(TP+FN)\n",
    "precision=TP/(TP+FP)\n",
    "false_pos_rate=FP/(FP+TN)\n",
    "fscore=(2*recall*precision)/(recall+precision)\n",
    "print(\"recall: \",recall,\"\\nprecision: \",precision,\"\\nFPR :\",false_pos_rate,\"\\nFscore :\",fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCRIISEiIkH/H6GtuDiUTCj2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d4fa37b6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Finding the right value for K\n",
    "#accuracies were found by training and testing on catalog 3 with different K values\n",
    "accuracies =[97.86492374727669,\n",
    "97.86492374727669,\n",
    "96.81917211328977,\n",
    "96.94989106753813,\n",
    "96.20915032679738,\n",
    "96.7755991285403,\n",
    "95.59912854030502,\n",
    "95.81699346405229,\n",
    "94.46623093681917,\n",
    "95.07625272331155,\n",
    "94.16122004357298,\n",
    "94.90196078431372,\n",
    "93.76906318082789,\n",
    "94.11764705882352,\n",
    "93.33333333333333,\n",
    "93.42047930283225,\n",
    "93.42047930283225,          \n",
    "92.72331154684096,\n",
    "92.50544662309368,\n",
    "93.11546840958606]\n",
    "error_rate=[]\n",
    "for i in accuracies:\n",
    "    #print(100-i)\n",
    "    error_rate.append(100-i)\n",
    "plt.plot([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12,13,14,15,16,17,18,19,20], error_rate)\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('error rate')\n",
    "plt.xlim(1, 20)\n",
    "plt.ylim(0, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
