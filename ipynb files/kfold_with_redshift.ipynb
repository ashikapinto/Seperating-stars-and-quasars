{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "\n",
    "#Upsampling\n",
    "data=pd.read_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\ML\\\\catalog3\\\\cat3.csv')\n",
    "df_majority=data[data['class']==1]\n",
    "df_minority = data[data['class']==0]\n",
    "df_minority_random=df_minority.sample(n=len(df_majority),replace=True)\n",
    "df_upsampled=pd.concat([df_majority,df_minority_random],axis=0)\n",
    "\n",
    "\n",
    "x=df_upsampled\n",
    "#x=df_upsampled.drop('class',axis=1)\n",
    "x=x.drop('galex_objid',axis=1)\n",
    "x=x.drop('sdss_objid',axis=1)\n",
    "#x=x.drop('spectrometric_redshift',axis=1)\n",
    "x=x.drop('pred',axis=1)\n",
    "x=x.drop('Unnamed: 0',axis=1)\n",
    "#converting into np.array\n",
    "x=x.values\n",
    "\n",
    "\n",
    "dataset=x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(df):\n",
    "    means_of_cols = [0 for i in range(len(df[0]))]\n",
    "    for i in range(len(df[0])):\n",
    "        column = [row[i] for row in df]\n",
    "        means_of_cols[i] = sum(column) / float(len(df))\n",
    "    return means_of_cols\n",
    "\n",
    "#Function to calculate the standard deviations of each of the columns\n",
    "def standard_deviation(df, means_of_cols):\n",
    "    std_of_cols = [0 for i in range(len(df[0]))]\n",
    "    for i in range(len(df[0])):\n",
    "        variance = [pow(x[i]-means_of_cols[i], 2) for x in df]\n",
    "        std_of_cols[i] = sum(variance)\n",
    "    std_of_cols = [sqrt(x/(float(len(df)-1))) for x in std_of_cols]\n",
    "    return std_of_cols\n",
    "\n",
    "# standardize\n",
    "def standardize(df, means_of_cols, std_of_cols):\n",
    "    for row in df:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - means_of_cols[i]) / std_of_cols[i]\n",
    "\n",
    "\n",
    "# function to calculate euclidean distance\n",
    "def distance(x1, x2, n):\n",
    "    d = 0\n",
    "    for x in range(n):\n",
    "        d += np.square(x1[x] - x2[x])\n",
    "    return np.sqrt(d)\n",
    "\n",
    "# KNN model\n",
    "def knn(train, y_train,test_row, k):\n",
    "    dist = {}\n",
    "    n = test_row.shape[0]\n",
    "    for x in range(len(train)):\n",
    "        d = distance(test_row, train[x], n)\n",
    "        dist[x] = d\n",
    "    #Ordered_dist contains the row numbers of the rows of the rows of the training data set ordered in the ascending order of \n",
    "    #the distance to the test instance\n",
    "    ordered_dist = sorted(dist.items(), key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for i in range(k):\n",
    "        neighbors.append(ordered_dist[i][0])\n",
    "    #Neighbors contains only the first K elements of the Ordered_dist\n",
    "    counts = {}  \n",
    "    for i in range(len(neighbors)):\n",
    "        target = y_train[neighbors[i]]\n",
    "        if target in counts:\n",
    "            counts[target] += 1\n",
    "        else:\n",
    "            counts[target] = 1\n",
    "    #Counts is a dictionary that keeps track of how many votes each of the outputs have recieved \n",
    "    ordered_count = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #Ordered count sorts this dictionary based on the number of votes and the function returns the target class with the maximum\n",
    "    #number of votes\n",
    "    return (ordered_count[0][0]) \n",
    "\n",
    "def accuracy(y_test, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(y_test)):\n",
    "        if y_test[x] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(y_test))) * 100.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.47643979057592\n",
      "99.60732984293193\n",
      "100.0\n",
      "100.0\n",
      "99.73821989528795\n",
      "100.0\n",
      "99.86910994764398\n",
      "99.86910994764398\n",
      "99.73821989528795\n",
      "99.73821989528795\n",
      "average 10 fold accuracy:  99.80366492146598\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "\n",
    "def split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            to_append = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(to_append))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "def kfold(dataset, n_folds):\n",
    "    folds = split(dataset, n_folds)\n",
    "    #print(folds[0])\n",
    "    acc=[]\n",
    "    for i in range(len(folds)):\n",
    "        train_set = list(folds)\n",
    "        train_set.pop(i)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set=folds[i]\n",
    "        #print(len(train_set))\n",
    "        #print(len(test_set))\n",
    "        y_train=[]\n",
    "        y_test=[]\n",
    "        #index 12 has the class\n",
    "        for i in train_set:\n",
    "            y_train.append(list(i).pop(12))\n",
    "        for i in test_set:\n",
    "            y_test.append(list(i).pop(12))\n",
    "        X_train=train_set\n",
    "        X_test=test_set\n",
    "        \n",
    "        means_of_cols = mean(X_train)\n",
    "        std_of_cols = standard_deviation(X_train, means_of_cols)\n",
    "\n",
    "\n",
    "        standardize(X_train, means_of_cols, std_of_cols)\n",
    "        standardize(X_test, means_of_cols, std_of_cols)\n",
    "        \n",
    "        predictions=[]\n",
    "        for i in range(len(X_test)):\n",
    "            predictions.append(knn(X_train,y_train,X_test[i],3))\n",
    "        print(accuracy(y_test,predictions))\n",
    "        acc.append(accuracy(y_test,predictions))\n",
    "    print(\"average 10 fold accuracy: \",sum(acc)/len(acc))   \n",
    "            \n",
    "        \n",
    "kfold(dataset,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
