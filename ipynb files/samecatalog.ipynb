{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.80918220946916\n",
      "True positives:  844\n",
      "False positives:  53\n",
      "True negatives:  1013\n",
      "False negatives:  181\n",
      "class 1 accuracy: 82.34146341463415\n",
      "class 0 accuracy: 95.0281425891182\n",
      "recall:  0.8234146341463414 \n",
      "precision:  0.9409141583054627 \n",
      "FPR : 0.04971857410881801 \n",
      "Fscore : 0.8782518210197711\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "\n",
    "#Upsampling\n",
    "data=pd.read_csv('C:\\\\Users\\\\HP\\\\Desktop\\\\ML\\\\catalog4\\\\cat4.csv')\n",
    "data = data.sample(n = 5000) \n",
    "df_majority=data[data['class']==1]\n",
    "df_minority = data[data['class']==0]\n",
    "df_minority_random=df_minority.sample(n=len(df_majority),replace=True)\n",
    "df_upsampled=pd.concat([df_majority,df_minority_random],axis=0)\n",
    "\n",
    "#splitting into y and x\n",
    "y=df_upsampled['class']\n",
    "#converting into np.array\n",
    "y=y.values\n",
    "#dropping some of the variables\n",
    "x=df_upsampled.drop('class',axis=1)\n",
    "x=x.drop('galex_objid',axis=1)\n",
    "x=x.drop('sdss_objid',axis=1)\n",
    "x=x.drop('spectrometric_redshift',axis=1)\n",
    "x=x.drop('pred',axis=1)\n",
    "x=x.drop('Unnamed: 0',axis=1)\n",
    "#converting into np.array\n",
    "x=x.values\n",
    "\n",
    "\n",
    "\n",
    "def split_into_train_test(x, y):\n",
    "    A = np.random.rand(x.shape[0])\n",
    "    split = A < np.percentile(A, 70)\n",
    "    #print(split)\n",
    "    X_test =  x[~split]\n",
    "    y_test = y[~split]\n",
    "    X_train = x[split]\n",
    "    y_train = y[split]\n",
    "    #print(len(X_train), len(y_train), len(X_test), len(y_test))\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "#Splitting into train and test data sets\n",
    "X_train, y_train, X_test, y_test = split_into_train_test(x,y) \n",
    "\n",
    "#Next we need to transform all the attributes to have 0 mean and standard deviation 1.This is essential because the larger \n",
    "#ranged attributes should not affect/contribute to the result more that the others.\n",
    "#i.e in the below functions we are imitating what the standard scalar function does.\n",
    "\n",
    "#Function to calculate the mean of each of the columns\n",
    "def mean(df):\n",
    "    means_of_cols = [0 for i in range(len(df[0]))]\n",
    "    for i in range(len(df[0])):\n",
    "        column = [row[i] for row in df]\n",
    "        means_of_cols[i] = sum(column) / float(len(df))\n",
    "    return means_of_cols\n",
    "\n",
    "#Function to calculate the standard deviations of each of the columns\n",
    "def standard_deviation(df, means_of_cols):\n",
    "    std_of_cols = [0 for i in range(len(df[0]))]\n",
    "    for i in range(len(df[0])):\n",
    "        variance = [pow(x[i]-means_of_cols[i], 2) for x in df]\n",
    "        std_of_cols[i] = sum(variance)\n",
    "    std_of_cols = [sqrt(x/(float(len(df)-1))) for x in std_of_cols]\n",
    "    return std_of_cols\n",
    "\n",
    "# standardize\n",
    "def standardize(df, means_of_cols, std_of_cols):\n",
    "    for row in df:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - means_of_cols[i]) / std_of_cols[i]\n",
    "\n",
    "\n",
    "means_of_cols = mean(X_train)\n",
    "std_of_cols = standard_deviation(X_train, means_of_cols)\n",
    "\n",
    "\n",
    "standardize(X_train, means_of_cols, std_of_cols)\n",
    "standardize(X_test, means_of_cols, std_of_cols)\n",
    "\n",
    "\n",
    "# function to calculate euclidean distance\n",
    "def distance(x1, x2, n):\n",
    "    d = 0\n",
    "    for x in range(n):\n",
    "        d += np.square(x1[x] - x2[x])\n",
    "    return np.sqrt(d)\n",
    "\n",
    "# KNN model\n",
    "def knn(train, test_row, k):\n",
    "    dist = {}\n",
    "    n = test_row.shape[0]\n",
    "    for x in range(len(train)):\n",
    "        d = distance(test_row, train[x], n)\n",
    "        dist[x] = d\n",
    "    #Ordered_dist contains the row numbers of the rows of the training data set ordered in the ascending order of \n",
    "    #the distance to the test instance\n",
    "    ordered_dist = sorted(dist.items(), key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for i in range(k):\n",
    "        neighbors.append(ordered_dist[i][0])\n",
    "    #Neighbors contains only the first K elements of the Ordered_dist\n",
    "    counts = {}  \n",
    "    for i in range(len(neighbors)):\n",
    "        target = y_train[neighbors[i]]\n",
    "        if target in counts:\n",
    "            counts[target] += 1\n",
    "        else:\n",
    "            counts[target] = 1\n",
    "    #Counts is a dictionary that keeps track of how many votes each of the outputs have recieved \n",
    "    ordered_count = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #Ordered count sorts this dictionary based on the number of votes and the function returns the target class with the maximum\n",
    "    #number of votes\n",
    "    return (ordered_count[0][0]) \n",
    "\n",
    "#Applying the model on the test data and storing the output in a list called predictions\n",
    "predictions=[]\n",
    "for i in range(len(X_test)):\n",
    "    predictions.append(knn(X_train,X_test[i],3))\n",
    "\n",
    "def accuracy(y_test, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(y_test)):\n",
    "        if y_test[x] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(y_test))) * 100.0\n",
    "\n",
    "\n",
    "print(accuracy(y_test,predictions))\n",
    "\n",
    "def confusionmatrix(y_actual, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    l0=0\n",
    "    l1=0\n",
    "    for i in range(len(y_pred)): \n",
    "        if(y_actual[i]==0):\n",
    "            l0+=1\n",
    "        elif(y_actual[i]==1):\n",
    "            l1+=1\n",
    "        if y_actual[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "    return(TP, FP, TN, FN,l0,l1)\n",
    "\n",
    "TP,FP,TN,FN,l0,l1=confusionmatrix(y_test,predictions)\n",
    "print(\"True positives: \",TP)\n",
    "print(\"False positives: \",FP)\n",
    "print(\"True negatives: \",TN)\n",
    "print(\"False negatives: \",FN)\n",
    "print(\"class 1 accuracy:\",((TP/l1)*100))\n",
    "print(\"class 0 accuracy:\",((TN/l0)*100))\n",
    "recall=TP/(TP+FN)\n",
    "precision=TP/(TP+FP)\n",
    "false_pos_rate=FP/(FP+TN)\n",
    "fscore=(2*recall*precision)/(recall+precision)\n",
    "print(\"recall: \",recall,\"\\nprecision: \",precision,\"\\nFPR :\",false_pos_rate,\"\\nFscore :\",fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
